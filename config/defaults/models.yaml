# multi_agent_llm_judge/config/defaults/models.yaml
models:
  gpt-4o:
    provider_id: "gpt-4o"
    input_cost_per_1k: 0.005
    output_cost_per_1k: 0.015
    context_window: 128000
  gpt-4o-mini:
    provider_id: "gpt-4o-mini"
    input_cost_per_1k: 0.00015
    output_cost_per_1k: 0.0006
    context_window: 128000
  gpt-4-turbo:
    provider_id: "gpt-4-turbo"
    input_cost_per_1k: 0.01
    output_cost_per_1k: 0.03
    context_window: 128000
